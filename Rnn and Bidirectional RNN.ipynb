{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PATH = 'http://ai.stanford.edu/~btaskar/ocr/letter.data.gz'\n",
    "DOWNLOAD_FILENAME = 'letter.data.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    if not os.path.exists(DOWNLOAD_FILENAME):\n",
    "        filename, _ = urllib.request.urlretrieve(URL_PATH, DOWNLOAD_FILENAME)\n",
    "    print('Found and verified file from this path: ',URL_PATH)\n",
    "    print('Download File: ', DOWNLOAD_FILENAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified file from this path:  http://ai.stanford.edu/~btaskar/ocr/letter.data.gz\n",
      "Download File:  letter.data.gz\n"
     ]
    }
   ],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines():\n",
    "    with gzip.open(DOWNLOAD_FILENAME, 'rt') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        lines = list(reader)\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = read_lines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52152"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', 'm', '3', '1', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_labels(lines):\n",
    "    \n",
    "    lines = sorted(lines, key=lambda x: int(x[0]))\n",
    "    \n",
    "    data, target = [], []\n",
    "    #-1 indicate that beginig a new word\n",
    "    next_id = -1\n",
    "    word = []\n",
    "    word_pixels = []\n",
    "    \n",
    "    for line in lines:\n",
    "        next_id = int(line[2])\n",
    "        \n",
    "        pixels = np.array([int(x) for x in line[6:134]])\n",
    "        pixels = pixels.reshape((16,8))\n",
    "        \n",
    "        word_pixels.append(pixels)\n",
    "        word.append(line[1])\n",
    "        \n",
    "        if next_id == -1:\n",
    "            data.append(word_pixels)\n",
    "            target.append(word)\n",
    "            \n",
    "            word = []\n",
    "            word_pixels = []\n",
    "            \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = get_features_labels(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 6877)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features_labels(data, target):\n",
    "    max_length = max(len(x) for x in target)\n",
    "    \n",
    "    padding = np.zeros((16,8))\n",
    "    \n",
    "    #Pad the image data with the empty string images\n",
    "    data = [x + ([padding] * (max_length - len(x))) for x in data]\n",
    "    \n",
    "    #Pad the word with empty string characters\n",
    "    target = [x + ([''] * (max_length - len(x))) for x in target]\n",
    "    \n",
    "    return np.array(data), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data, padded_target = pad_features_labels(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 6877)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_data), len(padded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', '']],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', '']],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length = len(padded_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14, -1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data.shape[:2] + (-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = padded_data.reshape(padded_data.shape[:2] + (-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " reshaped_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14, 26)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target.shape + (26,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_target = np.zeros(padded_target.shape + (26,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, letter in np.ndenumerate(padded_target):\n",
    "    if letter:\n",
    "        one_hot_target[index][ord(letter) - ord('a')] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_target[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(len(reshaped_data))\n",
    "shuffled_data = reshaped_data[shuffled_indices]\n",
    "shuffled_target = one_hot_target[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test set\n",
    "split = int(0.66 * len(shuffled_data))\n",
    "train_data = shuffled_data[:split]\n",
    "train_target = shuffled_target[:split]\n",
    "\n",
    "test_data = shuffled_data[split:]\n",
    "test_target = shuffled_target[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4538, 14, 128)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14 because each word is rapresent with a vector for length 14\n",
    "train_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4538, 14, 26)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 26 are the all letters of alphabet considerated (RAPRESENT THE CLASSES)\n",
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, num_steps, num_inputs = train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = train_target.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 128, 26)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps, num_inputs, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float64,[None, num_steps, num_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.placeholder(tf.float64,[None, num_steps, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "used = tf.sign(tf.reduce_max(tf.abs(X),reduction_indices=2))\n",
    "length = tf.reduce_sum(used, reduction_indices=1)\n",
    "sequence_length = tf.cast(length, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast:0' shape=(?,) dtype=int32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.GRUCell(num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float64, sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(300)])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share softmax layer\n",
    "weight = tf.Variable(tf.truncated_normal([num_neurons, num_classes], stddev=0.01, dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = tf.Variable(tf.constant(0.1, shape=[num_classes], dtype=tf.float64))\n",
    "flattened_output = tf.reshape(output, [-1, num_neurons])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 300) dtype=float64>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(flattened_output, weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_reshaped = tf.reshape(logits,[-1, num_steps, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = tf.not_equal(tf.argmax(Y,2), tf.argmax(logit_reshaped,2))\n",
    "mistakes = tf.cast(mistakes, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.sign(tf.reduce_max(tf.abs(Y), reduction_indices=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes *= mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = tf.reduce_sum(mistakes, reduction_indices=1)\n",
    "mistakes /= tf.cast(sequence_length, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = tf.reduce_mean(mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(0.002)\n",
    "gradient = optimizer.compute_gradients(loss)\n",
    "\n",
    "optimizer = optimizer.apply_gradients(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(data, target, batch_size):\n",
    "    \n",
    "    epoch = 0\n",
    "    offset = 0\n",
    "    \n",
    "    while True:\n",
    "        old_offset = offset\n",
    "        offset = (offset + batch_size) % (target.shape[0] - batch_size)\n",
    "        \n",
    "        #offset wrapper around to the beginning so new epoch\n",
    "        if offset < old_offset:\n",
    "            \n",
    "            #new epoch, ned to shuffle data\n",
    "            shuffled_indices = np.random.permutation(len(data))\n",
    "            \n",
    "            data = data[shuffled_indices]\n",
    "            target = target[shuffled_indices]\n",
    "            \n",
    "            epoch += 1\n",
    "        batch_data = data[offset:(offset + batch_size),:]\n",
    "        batch_target = target[offset:(offset + batch_size),:]\n",
    "        \n",
    "        yield batch_data, batch_target, epoch\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "batches = batched(train_data, train_target, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-62-2610eb40e6dc>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-62-2610eb40e6dc>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    feed = (X: batch_data, Y: batch_target)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for index, batch in enumerate(batches):\n",
    "        batch_data = batch[0]\n",
    "        batch_target = batch[1]\n",
    "        \n",
    "        epoch = batch[2]\n",
    "        if epoch >= epochs:\n",
    "            break\n",
    "        \n",
    "        feed = (X: batch_data, Y: batch_target)\n",
    "        train_error, _ = sess.run([error, optimizer], feed)\n",
    "        \n",
    "        print('(): {:3.6f}%', format(index + 1, 100*train_error))\n",
    "    \n",
    "    test_feed = {X: test_data, Y: test_target}\n",
    "    test_error, _ = sess.run([error, optimizer], test_feed)\n",
    "    \n",
    "    print('Test error: {:3.6f}%', format(100 * test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
